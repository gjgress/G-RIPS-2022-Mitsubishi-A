{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0348e61-51d1-44a7-90d8-1e87d0bd78da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f2499d1-d466-47c7-bfba-e0605416a0f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Map Matching Benchmarks\n",
    "\n",
    "This notebook is intended as a supplement to the Sendai Map notebook. This notebook implements the competing map matching algorithms and tests them against the map-matching-dataset for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6a375a-1580-42e2-8906-e25c32d3a587",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjgress/.local/lib/python3.10/site-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import osmnx as ox \n",
    "import time\n",
    "from shapely.geometry import Polygon, Point\n",
    "import os\n",
    "import ujson as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from algorithms import mm_utils\n",
    "import dask\n",
    "from functools import reduce\n",
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# Remove this when debugging\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import dask.bag as db\n",
    "\n",
    "%matplotlib inline\n",
    "#ox.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce2a800-3ab1-4794-ae6f-041e7807bb44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Input\n",
    "\n",
    "df_track = db.read_text('map-matching-dataset/*track.geojson').map(json.loads).map(gpd.GeoDataFrame.from_features)\n",
    "df_network_edges = db.read_text('map-matching-dataset/*arcs.geojson').map(json.loads).map(gpd.GeoDataFrame.from_features)\n",
    "df_network_nodes = db.read_text('map-matching-dataset/*nodes.geojson').map(json.loads).map(gpd.GeoDataFrame.from_features)\n",
    "df_gt = db.read_text('map-matching-dataset/*route.geojson').map(json.loads).map(gpd.GeoDataFrame.from_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ef7f7-b018-45ba-804c-71cf9b73da55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In our case, our data is already fused. But often you will have several datasets with asynchronous data that you will have to fuse first. We implemented a barebones method in mm_utils to handle this; you can see an example of how to use it in '02a Data Pre-Processing'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d1760-9488-4c9c-9122-9454d3eef862",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Typically GPS/IMU data is recorded as Point geometries in a GDF.\n",
    "However, some algorithms require a trajectory (LineStrings) despite this.\n",
    "As a result, our framework requires both points (nodes) and trajectories (edges).\n",
    "So we will need to create a \"trajectory\" by sequentially connecting our nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7172f1bc-ea8a-4ed7-b457-b3a8347252b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I wrote a utility function to do that, provided in mm_utils.\n",
    "\n",
    "df_track_edges = df_track.map(mm_utils.point_to_traj)#, columns = {'timestamp':'first',\n",
    "                                                     #  'altitude':'average',\n",
    "                                                     #  'speed':'average',\n",
    "                                                     #  'vertical accuracy':'last',\n",
    "                                                     #  'horizontal accuracy':'last',\n",
    "                                                     #  'oops':'notavalidmethod'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd175119-eb77-4056-be8c-587a0f92c181",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "There may be other data assigned to the nodes which we would like the edges to also reflect.\n",
    "Some algorithms may use the auxiliary data from edges, which is why this is a concern.\n",
    "There's no perfect way to do this assignment, but I included a few basic methods in mm_utils: 'first' node assignment, 'average' between nodes, and 'last' node assignment. That is the columns argument I used above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef35e6-a9c2-4873-b04c-4402c40e59ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now we demonstrate how we can work with several algorithms at once in a modular fashion.\n",
    "\n",
    "First we initialize the simulators, to be later applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17cbf4e-bd66-4e74-af39-f5aa1962fd35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from algorithms import metric_mm#, fmm_bin \n",
    "#from fmm import FastMapMatchConfig\n",
    "\n",
    "### Define map matching configurations\n",
    "\n",
    "k = 8\n",
    "radius = 0.003\n",
    "gps_error = 0.0005\n",
    "\n",
    "#fmm_config = FastMapMatchConfig(k,radius,gps_error)\n",
    "cfg_file = None\n",
    "\n",
    "## Least squares functions\n",
    "ls_ri = lambda distarray: np.square(distarray) # The function applied directly to the distances from the candidate route to the k-NN GPS coords\n",
    "ls_ro = lambda distarray: 1*(1/np.size(distarray) * np.sum(distarray)) # This is where we 'integrate' over the distances, and if we need to do anything else, we do it\n",
    "ls_gi = lambda distarray: np.square(distarray) # The function applied directly to the distances from the GPS coords to the k-NN candidate route nodes\n",
    "ls_go = lambda distarray: 1*(1/np.size(distarray) * np.sum(distarray))\n",
    "##\n",
    "\n",
    "## Inverse squares function ('Electrical method')\n",
    "eps = 0.0000001\n",
    "is_ri = lambda distarray: np.power(np.square(distarray) + eps, -1) # We need eps to prevent singularities, i.e. r = 0\n",
    "is_ro = lambda distarray: -1*(1/np.size(distarray) * np.sum(distarray)) # We sum, and then multiply by -1 to turn the minimizing process into a maximizing process\n",
    "is_gi = lambda distarray: np.power(np.square(distarray) + eps, -1)\n",
    "is_go = lambda distarray: -1*(1/np.size(distarray) * np.sum(distarray))\n",
    "##\n",
    "\n",
    "def wrapper_f(ri, ro, gi, go): # This should return a function composed from the basic functions, that can then be applied onto route and gps data.\n",
    "    return lambda route, gps : 1*ro(ri(route)) + 1*go(gi(gps))\n",
    "\n",
    "ls_loss_function = wrapper_f(ls_ri, ls_ro, ls_gi, ls_go)\n",
    "is_loss_function = wrapper_f(is_ri, is_ro, is_gi, is_go)\n",
    "\n",
    "def wasserstein(routeloss, gpsloss):#gpsloss,n,m\n",
    "    #the (i,j)th entry of the gpsloss matrix is the distance from the ith point of the trajectory to the jth point on the candiate route\n",
    "    # n is the number of points along the trajectory\n",
    "    # m is the number of points on the candidate route\n",
    "    n = gpsloss.shape[0]\n",
    "    m = gpsloss.shape[1]\n",
    "    #the (i,j)th entry of the gpsloss matrix is the distance from the ith point of the trajectory to the jth point on the candiate route\n",
    "    #Create equality constraints\n",
    "    b = [1/n for i in range(0,n)]+ [1/m for i in range(0,m)]\n",
    "    row1 = [i for i in range(0,n) for j in range(0,m)]\n",
    "    row2 = [n+j for j in range (0,m) for i in range(0,n)]\n",
    "    row = np.append(np.matrix.flatten(np.array(row1)),np.matrix.flatten(np.array(row2)))\n",
    "    col1 = [list(range(0,n*m))]\n",
    "    col2 =  [j+m*k for j in range(0,m) for k in range(0,n)]\n",
    "    col = np.append(np.matrix.flatten(np.array(col1)),np.matrix.flatten(np.array(col2)))\n",
    "    data = np.ones(n*m*2)\n",
    "    A = csr_matrix((data, (row, col)),shape = (n+m, n*m)).toarray()\n",
    "    A = A[:-1]\n",
    "    b = b[:-1]\n",
    "    #solve the linear program\n",
    "    res = linprog(np.matrix.flatten(gpsloss),None, None,A,b)\n",
    "    #return the function value, i.e. the wasserstein distance\n",
    "    loss = res.fun\n",
    "    return loss\n",
    "\n",
    "# The metric_mm algorithm allows you to either directly pass in a loss function, or to pass it all the individual pieces and wrap it itself\n",
    "# This may be useful in case you wish to utilize the individual functions of a sim elsewhere.\n",
    "\n",
    "#sim1 = fmm_bin.FMM(cfg = fmm_config)\n",
    "sim2 = metric_mm.Sim(ls_ri, ls_ro, ls_gi, ls_go, wrapper_f) # Least squares metric-based\n",
    "sim3 = metric_mm.Sim(loss_function = is_loss_function)\n",
    "sim4 = metric_mm.Sim(loss_function = wasserstein)\n",
    "\n",
    "\n",
    "## If you have the ground truth, load it here\n",
    "ground_truth = db.read_text('map-matching-dataset/*route.geojson').map(json.loads).map(gpd.GeoDataFrame.from_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3700509-e0bd-4622-8ead-922ca0c3960b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## We will convert our Dask Bags to Dask Delayed objects so we can iterate over them. Then we will lazily call our function on our dataset\n",
    "# Finally we will compute our results, and Dask will automatically parallelize our work.\n",
    "\n",
    "gt = ground_truth.to_delayed()\n",
    "te = df_track_edges.to_delayed()\n",
    "tn = df_track.to_delayed()\n",
    "ne = df_network_edges.to_delayed()\n",
    "nn = df_network_nodes.to_delayed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2092686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 278 µs, sys: 138 µs, total: 416 µs\n",
      "Wall time: 265 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We will precompute candidate routes for the first ten datasets, and then save them. This will greatly speed up the runtime of the metric-based loss methods and the Wasserstein loss methods.\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    if not os.path.exists('map-matching-dataset/0000000' + str(i) + 'candroutes.geojson'):\n",
    "    \n",
    "        network_edges = ne[i].compute()[0]\n",
    "        track_nodes = tn[i].compute()[0]\n",
    "                \n",
    "        qry_pts = [y for sublist in [x.coords[:] for x in network_edges['geometry']] for y in sublist]            \n",
    "        source_index, _ = mm_utils.get_nearest([(track_nodes['geometry'].iloc[0].x, track_nodes['geometry'].iloc[0].y)], qry_pts, k_neighbors = 1)\n",
    "        source_index = source_index[0][0]\n",
    "        target_index, _ = mm_utils.get_nearest([(track_nodes['geometry'].iloc[-1].x, track_nodes['geometry'].iloc[-1].y)], qry_pts, k_neighbors = 1)\n",
    "        target_index = target_index[0][0]\n",
    "\n",
    "        source = Point(qry_pts[source_index])\n",
    "        target = Point(qry_pts[target_index])\n",
    "\n",
    "        candidates = mm_utils.get_nearest_edges(track_nodes, network_edges, k_neighbors=8, r = 0.01) \n",
    "        all_candidate_edges = reduce(lambda left,right: pd.concat([left, right]).drop_duplicates(subset=['geometry']), candidates)\n",
    "        try:\n",
    "            candidate_routes, _ = mm_utils.dijkstra(source, target, all_candidate_edges) # This is the bottleneck in this situation. I wish I had time to write an informed Dijkstra method\n",
    "            with open('map-matching-dataset/0000000' + str(i) + 'candroutes.geojson', 'w') as f:\n",
    "                for j, item in enumerate(candidate_routes):\n",
    "                    if j > 0:\n",
    "                        f.write('\\n')\n",
    "                    f.write('%s' % item.to_json())\n",
    "                # Note that each line of the GeoJSON file is valid GeoJSON, but the file as a whole is not valid GeoJSON.\n",
    "        except:\n",
    "            with open('map-matching-dataset/0000000' + str(i) + 'candroutes.geojson', 'w') as f:\n",
    "                f.write('\\n')\n",
    "                # Create a blank file, so we won't try to run it again on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6190dfa-d701-4fa7-88fa-4289af592b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_edges = ne[9].compute()[0]\n",
    "# track_nodes = tn[9].compute()[0]\n",
    "                \n",
    "# qry_pts = [y for sublist in [x.coords[:] for x in network_edges['geometry']] for y in sublist]            \n",
    "# source_index, _ = mm_utils.get_nearest([(track_nodes['geometry'].iloc[0].x, track_nodes['geometry'].iloc[0].y)], qry_pts, k_neighbors = 1)\n",
    "# source_index = source_index[0][0]\n",
    "# target_index, _ = mm_utils.get_nearest([(track_nodes['geometry'].iloc[-1].x, track_nodes['geometry'].iloc[-1].y)], qry_pts, k_neighbors = 1)\n",
    "# target_index = target_index[0][0]\n",
    "\n",
    "# source = Point(qry_pts[source_index])\n",
    "# target = Point(qry_pts[target_index])\n",
    "\n",
    "# candidates = mm_utils.get_nearest_edges(track_nodes, network_edges, k_neighbors=16, r = 0.1) \n",
    "# all_candidate_edges = reduce(lambda left,right: pd.concat([left, right]).drop_duplicates(subset=['geometry']), candidates)\n",
    "\n",
    "# candidate_routes, _ = mm_utils.dijkstra(source, target, all_candidate_edges) # This is the bottleneck in this situation. I wish I had time to write an informed Dijkstra method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ad3754-3fc9-424f-ac6a-aff56a670eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we want to reconstruct this list, we do the following:\n",
    "\n",
    "all_cands = []\n",
    "\n",
    "for i in range(2):\n",
    "    cand_routes = []\n",
    "    with open('map-matching-dataset/0000000'+ str(i) + 'candroutes.geojson', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            gjson = json.loads(line)\n",
    "            cand_routes.append(gpd.GeoDataFrame.from_features(gjson))\n",
    "    all_cands.append(cand_routes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec4583-0502-4ac8-bfce-3129cd9264d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now we are ready to run the simulator on a subsection (or all of) the data. Notice how easy it is to run algorithms in parallel-- all of the parallelization is handled by Dask Delayed, so even though our algorithm is only designed to handle one case at a time, it has already gained magnitudes of efficiency.\n",
    "\n",
    "One small caveat-- even if your algorithm is technically 'independent', if you utilize python.os functions, you may run into I/O read/write errors. To circumvent this, use a dedicated library such as tempfile to systematically handle the temp file creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aedea5e-60ba-40a3-ab47-b834b5ed47de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 37s ± 31.3 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "15.2 s ± 540 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2min 40s ± 5.24 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "15.6 s ± 615 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "8min 18s ± 28.6 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "10.1 s ± 595 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "7min 53s ± 22.7 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "13.1 s ± 332 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## Let's see this!\n",
    "sim2_results = []\n",
    "sim3_results = []\n",
    "#sim4_results = []\n",
    "\n",
    "n = 2\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    ite = te[i].compute()[0]\n",
    "    itn = tn[i].compute()[0]\n",
    "    ine = ne[i].compute()[0]\n",
    "    inn = nn[i].compute()[0]\n",
    "    \n",
    "    # Load candidate routes\n",
    "    \n",
    "    cand_routes = []\n",
    "    with open('map-matching-dataset/0000000' + str(i) + 'candroutes.geojson', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            gjson = json.loads(line)\n",
    "            cand_routes.append(gpd.GeoDataFrame(gjson))\n",
    "#    %timeit sim1_results.append(sim1.run(ite, itn, ine, inn, return_results=True))\n",
    "    \n",
    "    %timeit sim2.preprocessing(ite, ine, candidate_routes = all_cands[i], n = 10, m = 1)\n",
    "    %timeit sim2_results.append(sim2.run(k1 = 10, k2 = 10, return_results = True)[0])\n",
    "    \n",
    "    %timeit sim3.preprocessing(ite, ine, candidate_routes = all_cands[i], n = 10, m = 1)\n",
    "    %timeit sim3_results.append(sim3.run(k1 = 10, k2 = 10, return_results = True)[0])\n",
    "    \n",
    "#    %timeit sim4.preprocessing(ite, ine, candidate_routes = all_cands[i], n = 1, m = 1)\n",
    "#    %timeit sim4_results.append(sim4.run(k1 = 1, k2 = -1, return_results = True)[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8694de-546f-40ac-a420-aed96ad984d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now we iterate through our results, and evaluate it using the build-in evaluation method in mm_utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1274f1a5-6725-4ec8-b4da-3fe6c5b314c6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Currently only array-like objects can be matched; please choose a different match column.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/G-RIPS-2022-Mitsubishi-A/Code/algorithms/mm_utils.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(prediction, gt, matchid)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatchid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatchid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mintersect1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36mintersect1d\u001b[0;34m(ar1, ar2, assume_unique, return_indices)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n",
      "\u001b[0;32m/usr/lib/python3.10/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'LineString' and 'LineString'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54031/3192682511.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                                    gt[i].compute()[0],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#                                    matchid = \"index\")) # A more standard match method would be 'geometry', but in this case index is more reliable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     sim2_errors.append(mm_utils.evaluate(sim2_results[i],\n\u001b[0m\u001b[1;32m     13\u001b[0m                                     \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                     matchid = \"geometry\"))\n",
      "\u001b[0;32m~/G-RIPS-2022-Mitsubishi-A/Code/algorithms/mm_utils.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(prediction, gt, matchid)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatchid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatchid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Currently only array-like objects can be matched; please choose a different match column.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mevalint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatchid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatchid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Currently only array-like objects can be matched; please choose a different match column."
     ]
    }
   ],
   "source": [
    "#sim1_errors = []\n",
    "sim2_errors = []\n",
    "sim3_errors = []\n",
    "#sim4_errors = []\n",
    "\n",
    "for i in range(len(sim2_results)):\n",
    "#    errors.append(dask.delayed(mm_utils.evaluate)(sim1_results[i],gt[i], matchid = \"index\")) # A more standard match method would be 'geometry', but in this case index is more reliable\n",
    "# For whatever reason, delayed isn't working here, so I'm just going to do this manually\n",
    "#    sim1_errors.append(mm_utils.evaluate(sim1_results[i],\n",
    "#                                    gt[i].compute()[0],\n",
    "#                                    matchid = \"index\")) # A more standard match method would be 'geometry', but in this case index is more reliable\n",
    "    sim2_errors.append(mm_utils.evaluate(sim2_results[i],\n",
    "                                    gt[i].compute()[0],\n",
    "                                    matchid = \"index\"))\n",
    "    sim3_errors.append(mm_utils.evaluate(sim3_results[i],\n",
    "                                    gt[i].compute()[0],\n",
    "                                    matchid = \"index\"))\n",
    "#    sim4_errors.append(mm_utils.evaluate(sim4_results[i],\n",
    "#                                    gt[i].compute()[0],\n",
    "#                                    matchid = \"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703e368-b73f-4486-85b8-f6957d1fc51e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(1)\n",
    "# plt.boxplot(sim1_errors,vert=False)\n",
    "# plt.title('FMM Error %s on ' \n",
    "#           + str(n) \n",
    "#           + ' test cases \\n(Average error = ' \n",
    "#           + str(np.average(sim1_errors)) + ')')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f17e01-a7e3-4ab6-8cdb-ca69c0930401",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.boxplot(sim2_errors,vert=False)\n",
    "plt.title('Least Squares Error %s on ' \n",
    "          + str(n) \n",
    "          + ' test cases \\n(Average error = ' \n",
    "          + str(np.average(sim2_errors)) + ')')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b93275-456b-4b9f-b74c-14b0349d467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.boxplot(sim3_errors,vert=False)\n",
    "plt.title('Electrical Method Error %s on ' \n",
    "          + str(n) \n",
    "          + ' test cases \\n(Average error = ' \n",
    "          + str(np.average(sim3_errors)) + ')')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a30cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(1)\n",
    "# plt.boxplot(sim4_errors,vert=False)\n",
    "# plt.title('Wasserstein Error %s on ' \n",
    "#           + str(n) \n",
    "#           + ' test cases \\n(Average error = ' \n",
    "#           + str(np.average(sim4_errors)) + ')')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37561430-9bb6-4050-9462-1edb27639615",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Overall, FMM seems to handle itself okay, with the exception of one huge outlier!\n",
    "\n",
    "(Note-- having an error above 100% is not a bug; the standard error formula is not upper-bounded, despite being a percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56649bdd-313c-40d6-8393-c54390516672",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Let's see how they performed on one datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f79374-74f1-4fbe-a345-e4ec7b33596a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "fig, axs = plt.subplots(2,n, figsize=(24,16))\n",
    "\n",
    "fig.suptitle('Evaluation Methods Visualized')\n",
    "\n",
    "# netemp = ne[0].compute()[0]\n",
    "# gttemp = gt[0].compute()[0]\n",
    "# netemp.plot(ax=axs[0,0])\n",
    "# tn[0].compute()[0].plot(ax=axs[0,0], color='black',markersize=2)\n",
    "# netemp.plot(ax=axs[1,0])\n",
    "# gttemp.plot(ax=axs[1,0], color='green')\n",
    "# netemp.plot(ax=axs[2,0])\n",
    "# sim1_results[0].plot(ax=axs[2,0], color= 'red')\n",
    "# evalint = gttemp.loc[np.intersect1d(gttemp['index'], sim1_results[0]['index'], return_indices=True)[1]]\n",
    "# evalxor = pd.concat([gttemp.overlay(evalint, how=\"difference\"), sim1_results[0].overlay(evalint, how = \"difference\")])\n",
    "# evalxor.plot(ax=axs[3,0], color='purple')\n",
    "# axs[3,0].text(0.5, -0.5, 'Error: ' + str(sim1_errors[0]), size=10, ha= 'center', transform=axs[3,0].transAxes)\n",
    "\n",
    "netemp = ne[0].compute()[0]\n",
    "gttemp = gt[0].compute()[0]\n",
    "netemp.plot(ax=axs[0,0])\n",
    "tn[0].compute()[0].plot(ax=axs[0,0], color='black',markersize=2)\n",
    "netemp.plot(ax=axs[1,0])\n",
    "gttemp.plot(ax=axs[1,0], color='green')\n",
    "netemp.plot(ax=axs[2,0])\n",
    "sim2_results[0].plot(ax=axs[2,0], color= 'red')\n",
    "evalint = gttemp.loc[np.intersect1d(gttemp['index'], sim2_results[0]['index'], return_indices=True)[1]]\n",
    "evalxor = pd.concat([gttemp.overlay(evalint, how=\"difference\"), sim2_results[0].overlay(evalint, how = \"difference\")])\n",
    "evalxor.plot(ax=axs[3,0], color='purple')\n",
    "axs[3,0].text(0.5, -0.5, 'Error: ' + str(sim2_errors[0]), size=10, ha= 'center', transform=axs[3,0].transAxes)\n",
    "\n",
    "netemp = ne[0].compute()[0]\n",
    "gttemp = gt[0].compute()[0]\n",
    "netemp.plot(ax=axs[0,1])\n",
    "tn[0].compute()[0].plot(ax=axs[0,1], color='black',markersize=2)\n",
    "netemp.plot(ax=axs[1,1])\n",
    "gttemp.plot(ax=axs[1,1], color='green')\n",
    "netemp.plot(ax=axs[2,1])\n",
    "sim3_results[0].plot(ax=axs[2,1], color= 'red')\n",
    "evalint = gttemp.loc[np.intersect1d(gttemp['index'], sim3_results[0]['index'], return_indices=True)[1]]\n",
    "evalxor = pd.concat([gttemp.overlay(evalint, how=\"difference\"), sim3_results[0].overlay(evalint, how = \"difference\")])\n",
    "evalxor.plot(ax=axs[3,1], color='purple')\n",
    "axs[3,1].text(0.5, -0.5, 'Error: ' + str(sim3_errors[0]), size=10, ha= 'center', transform=axs[3,1].transAxes)\n",
    "\n",
    "# netemp = ne[0].compute()[0]\n",
    "# gttemp = gt[0].compute()[0]\n",
    "# netemp.plot(ax=axs[0,2])\n",
    "# tn[0].compute()[0].plot(ax=axs[0,2], color='black',markersize=2)\n",
    "# netemp.plot(ax=axs[1,2])\n",
    "# gttemp.plot(ax=axs[1,2], color='green')\n",
    "# netemp.plot(ax=axs[2,2])\n",
    "# sim4_results[0].plot(ax=axs[2,2], color= 'red')\n",
    "# evalint = gttemp.loc[np.intersect1d(gttemp['index'], sim4_results[0]['index'], return_indices=True)[1]]\n",
    "# evalxor = pd.concat([gttemp.overlay(evalint, how=\"difference\"), sim3_results[0].overlay(evalint, how = \"difference\")])\n",
    "# evalxor.plot(ax=axs[3,2], color='purple')\n",
    "# axs[3,2].text(0.5, -0.5, 'Error: ' + str(sim4_errors[0]), size=10, ha= 'center', transform=axs[3,2].transAxes)\n",
    "\n",
    "\n",
    "fig.legend(handles=[axs[0,0].collections[0],axs[0,0].collections[1],axs[1,0].collections[1],axs[2,0].collections[1],axs[3,0].collections[0]], labels = ['Road Network', 'GPS Datapoints', 'Ground Truth', 'Prediction', 'Difference between GT and Pred.'], loc = 'lower left')\n",
    "plt.savefig(\"image.png\",bbox_inches='tight',dpi=100) \n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
