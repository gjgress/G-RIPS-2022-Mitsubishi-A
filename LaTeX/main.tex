\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath,amsthm,amsfonts,amssymb}

\usepackage{xcolor}%used to color text
% \usepackage{mathabx}
\usepackage{graphicx,tikz,setspace}
\usepackage[margin=2.5cm]{geometry}
\usepackage[colorlinks=true]{hyperref}
% \usepackage{float}
% \usepackage{array}
% \usepackage{listings}
% \usepackage{hhline}
% \usepackage[numbered,framed]{matlab-prettifier}
% \usepackage{fancyvrb}
\usepackage{mathtools}
% \usepackage{multirow}
% \usepackage{algorithm2e}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{indentfirst}
\usetikzlibrary{positioning}
\usetikzlibrary{topaths,calc}
\usepackage{here}
\usepackage{aliascnt}

\usepackage[english]{babel}  %なんかsubsectionとかをautorefで引用したときに先頭の``S"を大文字にしてくれる呪文らしい
\addto\extrasenglish{\def\subsubsectionautorefname{\S}}
\addto\extrasenglish{\def\subsectionautorefname{\S}}
\addto\extrasenglish{\def\sectionautorefname{Section}}

\usepackage{fancyhdr}
\usepackage{lastpage}

\usepackage{tikz}
\usetikzlibrary{arrows,shapes, fit}
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm,
    minimum height=2em]


% \usepackage{pgfplots}
% \pgfplotsset{compat=1.15}
% \newenvironment{solution}
%   {\renewcommand\qedsymbol{$\vartriangleleft$}\begin{proof}[Solution]}
%   {\end{proof}}

\numberwithin{equation}{section}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newaliascnt{example}{definition} %Example
\newtheorem{example}[example]{Example}
\aliascntresetthe{example}
\newcommand{\exampleautorefname}{Example}
\newaliascnt{remark}{definition} %Remark
\newtheorem{remark}[remark]{Remark}
\aliascntresetthe{remark}
\newcommand{\remarkautorefname}{Remark}
\newaliascnt{prob}{definition} %Problem
\newtheorem{prob}[prob]{Problem}
\aliascntresetthe{prob}
\newcommand{\probautorefname}{Problem}

%%%%%
\newcommand{\ninni}{{}^\forall} %∀
\newcommand{\aru}{{}^\exists} %∃
\newcommand{\dis}{\displaystyle} 
\newcommand{\A}{\alpha}
\newcommand{\B}{\beta}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\de}{\delta}
\newcommand{\dex}{\delta_x}
\newcommand{\dey}{\delta_y}
\newcommand{\K}{\kappa}
\newcommand{\la}{\lambda}
\newcommand{\N}{\mathbb{N}}
\newcommand{\NN}{\mathcal{N}}
\newcommand{\PP}{\mathscr{P}}
\newcommand{\R}{\mathbb{R}} 
\newcommand{\RR}{\mathbb{R}_{\geq 0}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\ttilde}{\widetilde} %大きいチルダ
\newcommand{\eps}{\varepsilon} %ε
\newcommand{\uto}{\uparrow}
\newcommand{\dto}{\downarrow}
\newcommand{\rv}{\mathbb{R}^V} 
\newcommand{\expo}{\mathsf{exp}}
\newcommand{\vol}{\mathsf{vol}}
\newcommand{\mt}{\mathsf{MT}}
\newcommand{\ttt}{\mathsf{TT}}
\DeclareMathOperator\supp{supp} %supp
\newcommand{\argmax}{\mathop{\rm arg\,max}\limits} %argmax
\newcommand{\argmin}{\mathop{\rm arg\,min}\limits} %argmin
\newcommand{\rwx}{\mu_x^\alpha} %xでのr.w.
\newcommand{\rwy}{\mu_y^\alpha} %yでのr.w.
\newcommand{\wxy}{W_1\big(m_x^\alpha,m_y^\alpha\big)}
\newcommand{\whxy}{W_h\big(m_x^\alpha,m_y^\alpha\big)}
\newcommand{\kaxy}{\kappa(\alpha;x,y)}
\newcommand{\tkaxy}{\tilde{\kappa}(\alpha,h;x,y)}
\newcommand{\kxy}{\kappa(x,y)}
\newcommand{\tkxy}{\tilde{\kappa}(h;x,y)}
\newcommand{\kLLYxy}{\kappa_{\textrm{LLY}}(x,y)}
\newcommand{\lip}{\textsf{Lip}(V)}
\def\:={\coloneqq} %:=
\def\bu{$\bullet$ }
\def\comar{$\rightsquigarrow$}%ぐにゃぐにゃのヤツ
\def\dcomar{$\downrsquigarrow$}%下向きぐにゃぐにゃ
\def\kakko<#1>{\left\langle #1 \right\rangle}
\def\diam(#1){\mathsf{diam}(#1)}
%\def\vol(#1){\mathsf{vol}(#1)}
\def\W(#1){W_1\big(#1\big)}
\def\wh(#1){W_h\big(#1\big)}
\def\conv(#1){\textrm{conv}\left( #1 \right)}
\def\01{\{0,1\}}
\def\L(#1){#1\textrm{-Lip}}
\def\w-#1-Lip{\textrm{w-}$#1$\textrm{-Lip}}
\def\3|{|\hspace{-0.4mm}|\hspace{-0.4mm}|}
\def\Lip(#1){\textsf{Lip}_w^{#1}(V)}
\def\blue(#1){\textcolor{blue}{#1}}
\def\red(#1){\textcolor{red}{#1}}
\def\green(#1){\textcolor{green}{#1}}
%%%%%


% \newcommand{\bmb}{\begin{bmatrix}}
% \newcommand{\bme}{\end{bmatrix}}
% \newcommand\norm[1]{\left\lVert#1\right\rVert}
% \DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
% \newcommand{\st}{\text{s.t.}}
% \newcommand{\E}[2]{\ensuremath{{\mathbb{E}_{#1}}{\left[{#2}\right]}}}
% \newcommand{\R}{\ensuremath{\mathbb{R}}}
% \DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

% https://www.overleaf.com/learn/latex/Bibtex_bibliography_styles
\bibliographystyle{unsrt}

\title{Mitsubishi-A Work Statement}
\author{}
\date{}

\pagestyle{fancy}
\fancyhf{}
 
\lhead{Page \thepage \hspace{1pt} of \pageref{LastPage}}
\rhead{g-RIPS Sendai 2022, Mitsubishi-A}
\cfoot{\thepage}

\begin{document}
\nocite{*}% for bibilography


\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE g-RIPS Sendai 2022}\\[1.5cm] % Name of your university/college
\textsc{\Large Mitsubishi-A Group}\\[0.5cm] % Major heading such as course name
%\textsc{\large Minor Heading}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Work Statement}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Authors:}\\
 \textsc{Tomoya Akamatsu}\textsuperscript{1} \\ % Your name \\ 
 \textsc{Gabriel Gress}\textsuperscript{2}\\
 \textsc{Katelynn Huneycutt}\textsuperscript{3}\\
  \textsc{Seiya Omura }\textsuperscript{4}\\
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Mentors:} \\
 \textsc{Shunsuke Kano}\textsuperscript{+}\\% \\% Supervisor's Name
 \textsc{Masashi Yamazaki}\textsuperscript{*} 
\end{flushright}
\end{minipage}\\[0.5cm]
\center\begin{minipage}{0.35\textwidth}
\begin{flushleft}\small

\textsuperscript{1} Osaka University\\
\textsuperscript{2} University of New Mexico\\
\textsuperscript{3} Ohio State University \\
\textsuperscript{4} Nagoya University \\
\textsuperscript{*} Industrial Mentor, MITSUBISHI Electric Corp \\
\textsuperscript{+} Academic Mentor, Tohoku University, Aobayama campus \\

\end{flushleft}
\end{minipage}\\[2cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

%\includegraphics{logo.png}\\[1cm] % Include a department/university logo - this will require the graphicx package
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\tableofcontents \newpage

\section{Introduction}
A fundamental question when dealing with geospatial information is, given GPS trajectory data and a road map, how can one determine which route on a map this trajectory corresponds to. The aim of our project is to develop new map matching algorithms, favoring mathematical, rather than a data driven, formulations that are less sensitive to changes in road networks and noise in trajectory data. We propose three novel methods: inner product, Wasserstein distance, and coordinate transformation methods.   

\begin{itemize}
    \item Applications
    \item What is map matching?
    \item summarize our project plan
\item associated challenges 
\end{itemize}


\section{Problem Summary and Statement}


We will adopt the problem statement from definitions 2.1-2.4 in \cite{C}. 

\begin{definition}[Trajectory]
A \textbf{trajectory} $Tr$ is a sequence points $p_1\rightarrow p_2 \rightarrow \dots \rightarrow p_n$. Each point $p_i$ consists of a coordinate $( x_i,y_i)\in \mathbb{R}^2$ , a timestamp $t_i$, a speed $spd_i$ (optional) and a heading $\theta_i$ (optional). i.e.:  $p_i=( x_i,y_i,t_i,spd_i,\theta_i )$.
\end{definition}

\begin{definition}[Road Network]
A  \textbf{road network} (also known as map) is a directed graph $G=(V,E)$ embedded in $\mathbb{R}^2$, with vertices $v=(x,y)\in V$ and edges $e = (s, f, l)$  between vertices $s$ to $f$  where $s,f\in V$ connected by a polyline $l$ represented by a sequence of points in $\mathbb{R}^2$. %{\color{red} Perhaps we should say something about the graph being embedded in $\mathbb{R}^2$}

% A  \textbf{road network} (also known as map) is a directed graph $G=(V,E)$ embedded in $\mathbb{R}^2$, in which a vertex $v=(x,y)\in V$  represents an intersection or a road end, and an edge $e = (s, f, l)$ is a directed road starting from vertices $s$ to $d$ with a polyline $l$ represented by a sequence of spatial points. {\color{red} Perhaps we should say something about the graph being embedded in $\mathbb{R}^2$}
% \begin{remark}

% \end{remark}
\end{definition}

\begin{definition}[Route]
A  \textbf{route} $R$ represents a sequence of connected edges, i.e. $R = e_1\rightarrow e_2 \rightarrow \dots \rightarrow e_n$, {\color{blue} where for all $1\leq i\leq n$, $e_i=(s_i,f_i,l_i)$ and $f_i =s_{i+1}$.}%{ \color{red}$e_i\in G.E (1\leq i\leq n)$ and $e_k.e=e_{k+1}.s$ needs clarification} 
\end{definition}

\begin{definition}[Map-Matching]
Given a road network $G(V, E)$ and a trajectory
$Tr$, the map-matching find a route $\mathcal{MR}_G(Tr)$ that represents the  by the trajectory.
\end{definition}

\begin{remark}
In application, the trajectory is the geospatial data collected while traveling is the trajectory and the actual paths possibly traveled are modeled by the road network. The goal of map matching is given a trajectory and a road network to find a route to represent that actual path taken. 
\end{remark}
 %Given a road network $G(V, E)$ and a trajectory
% $Tr$, the map-matching find a route $\mathcal{MR}_G(Tr)$ that represents the sequence of roads travelled by the trajectory.



    
%We have adhere to a standard setting of map matching which is to consider a map as a graph in $\mathbb{R}^2$



\section{Background}

In this section, we will review two existing map matching techniques and evaluate their strengths and weaknesses. Surveys of existing map matching algorithms are available in \cite{C,Q}. We will provide both and example of a geometric and machine learning approach to map matching. 
In addition, we will present an introduction to discrete optimal transport theory which will be necessary for the explanation of one of our proposed map matching algorithms.
% \begin{itemize}
%     \item geometric methods 
%     \item machine learning methods
% %{\color{red}   \item methods available in patents... Haven't found any worth talking about yet  }
% \end{itemize}
\subsection{Geometric Methods}
% Many elementary techniques fall into the category of geometric methods. 
Descriptions of several geometric methods including point-to-point, point-to-to curve, and curve-to-curve methods can be found in \cite{BK}. The simplest geometric map matching algorithms is the point-to-point method. The procedure for the point-to-point method is given in \cite{BK} to be
\begin{enumerate}
\item Compute the distance between the coordinates of each trajectory point $p_i$ to each vertex $(x,y)\in V\subset \mathbb{R}^2$.
\item Match trajectory point $p_i$ to the vertex $(x,y)\in V$ with the shortest distance. 
{\color{red} This doesn't exactly align with our model or section 2} 
%\item Join these matched vertices using the shortest avaliable polyline of edges  
%\item {\color{red} Choose a route to be a polyline between matched vertices }
\end{enumerate}
Geometric methods like the point-to-point method are easily implemented and have low computational time \cite{BK}. Techniques such as creating Voronoi diagrams can be used to further decrease computational time. For example, one can partition a subset of $\mathbb{R}^{2}$ based on which points are closer to a given node on the graph than all others. This partition could be computed once and used to for map matching different trajectories on the same road network. See figure \ref{voronoi} for an example of a Voronoi diagram of a road network. The black lines and circles in the figure correspond to the road network while the blue lines partition the space into regions whose points are closest to the given node.
\begin{figure}[h!]
    \centering
    \includegraphics[scale=.25]{Voronoi.png}
    \caption{Voronoi Example}
    \label{voronoi}
\end{figure}

However, this method, and other geometric methods can be sensitive to measurement errors and are highly dependent on the network structure \cite{BK}. Bernstein and Kornhauser presented the example in figure \ref{GME} to demonstrate this. Suppose the sequence of red points labeled $x_1,x_2,x_3$ are our trajectory and the lines and circles represent the vertices and edges of the underlying road network. Clearly, the trajectory appears to be closest to the path from vertex $v_4$ to $v_5$, but the closest node to trajectory point $x_2$ is $v_2$.

\begin{figure}[h!]
    \centering
\begin{tikzpicture}[]
    \node[shape=circle,draw=black] (A) at (0,0) {$v_1$};
    \node[shape=circle,draw=black] (B) at (3,0) {$v_2$};
    \node[shape=circle,draw=black] (C) at (6,0) {$v_3$};
    \node (x1) at (-.5,-1.2) {\red($x_1$)};
    \node (x2) at (2.5,-1.1) {\red($x_2$)};
    \node (x3) at (5.5,-1.2) {\red($x_3$)};
    \path [-] (A) edge node[left] {} (B);
    \path [-] (B) edge node[left] {} (C);
    \node[shape=circle,draw=black] (A) at (0,-1.5) {$v_4$};
    \node[shape=circle,draw=black] (C) at (6,-1.5) {$v_5$};
    \path [-] (A) edge node[left] {} (C);
 \end{tikzpicture}
    \caption{Geometric Method Error }
    \label{GME}
\end{figure}


\subsection{Data Driven Methods}

The use of Hidden Markov Models (HMM) is one of the most popular approaches to the map matching problem \cite{C}. An open source example of a map matching algorithm using HMM is GraphHopper \cite{graphhopper}. 

\begin{figure}[h!]
    \centering
\begin{tikzpicture}[]
    \node[shape=circle,draw=black] (y1) at (0,0) {$y_1$};
    \node[shape=circle,draw=black] (y2) at (1.5,0) {$y_2$};
    \node[draw=none] (ellipsis1) at (3,0) {$\cdots$};
    \node[shape=circle,draw=black] (yN) at (4.5,-0) {$y_{N}$};
     \node[shape=circle,draw=black,fill=gray!40] (x1) at (0,-1.5) {$x_1$};
    \node[shape=circle,draw=black,fill=gray!40] (x2) at (1.5,-1.5) {$x_2$};
    \node[draw=none] (ellipsis2) at (3,-1.5) {$\cdots$};
    \node[shape=circle,draw=black, fill=gray!40] (xN) at (4.5,-1.5) {$x_{N}$};

    \path [->] (y1) edge node[left] {} (y2);
    \path [->](y2) edge node[left] {} (ellipsis1);
     \path [->](ellipsis1) edge node[left] {} (yN);
     \path [->](y1) edge node[left] {} (x1);
     \path [->](y2) edge node[left] {} (x2);
     \path [->](yN) edge node[left] {} (xN);

\end{tikzpicture}
    \caption{Hidden Markov Model (HMM)}
    \label{HMM}
\end{figure}

\subsubsection{General Idea} A Markov chain is a probabilistic model for sequential events subject to the condition that the probability of a given event depends on the on the previous event alone, i.e.  it is a sequence of random variable $z_1,...z_n$ satisfying
\begin{align}
    p(z_n| z_1,\dots z_{n-1}) =  p(z_n| z_{n-1}).
\end{align}
% \begin{figure}[h!]
%     \centering
% \begin{tikzpicture}[]
%     \node[shape=circle,draw=black] (y1) at (0,0) {$Y_1$};
%     \node[shape=circle,draw=black] (y2) at (1.5,0) {$Y_2$};
%     \node[draw=none] (ellipsis1) at (3,0) {$\cdots$};
%     \node[shape=circle,draw=black] (yN) at (4.5,-0) {$Y_{N}$};

%     \path [->] (y1) edge node[left] {} (y2);
%     \path [->](y2) edge node[left] {} (ellipsis1);
%      \path [->](ellipsis1) edge node[left] {} (yN);
% \end{tikzpicture}
%     \caption{Markov Chain}
%     \label{fig:my_label}
% \end{figure}


A Hidden Markov Model assumes that observations, $x_1,x_2,\dots x_n$ are generated by a Markov chain of unobserved states $y_1,\dots,y_n$, seen in \ref{HMM}. The joint probability of the observed and unobserved states is
\begin{align*}
    p(x_1,x_2,\dots x_n,y_1,\dots,y_n) = p(y_1)p(x_1|y_1) \prod_{i=2}^n p(y_i|y_{i-1})p(x_i|y_i).
\end{align*}
The probability $p(x_i|y_i)$ is called the emission probability, $p(y_{i}|y_{i-1})$ is the transition probability, and $p(y_1)$ is the initial distribution. If there are a finite number of states each $x_i$ and $y_i$ can take on, then we can form emission and transition matrices. Once these parameters are established, one of several existing algorithms can be used to solve probabilities of sequences of $y_i$'s take on specific values given the observed $x_i$'s. 



\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[]
        \node[shape=circle,draw=black,minimum size=1.5cm] (Bu) at (0,0) {Busy};
        \node[shape=circle,draw=black,,minimum size=1.5cm] (NBu) at (4,0) {Not Busy};
        \node[shape=circle,draw=black,minimum size=1.5cm] (G) at (.5,-3) {Good};
        \node[shape=circle,draw=black,minimum size=1.5cm] (B) at (3.5,-3) {Bad};
            
        \path[->] (Bu)edge [loop left] node {.7} (Bu);    
        \path [->](NBu) edge[bend right] node [above] {.6} (Bu);
        \path [<-](NBu) edge[bend left] node [above] {.3} (Bu);
        \path[->] (NBu) edge [loop right] node {.4} (NB);   
        \path [->] (Bu) edge node[left] {.2}  (G) ; 
        \path [->] (Bu) edge node [left] {.8} (B) ; 
        \path [->] (NBu) edge node[right] {.9}  (G) ; 
        \path [->] (NBu) edge node[right] {.1}  (B); 
    \end{tikzpicture}
    \caption{Transition and Emission probabilities for Example 3.1 }
    \label{TrEm}

\end{figure}
\begin{example} 
A simple application of an HMM can be used to determine how busy a teacher is, given the observed lecture quality. Take the observed states $x_1,\dots,x_n\in \{\text{good, bad}\}$ to be the quality of the lecture on days $1,\dots, n$, and the unobserved states to be $y_1,\dots,y_n\in \{\text{busy, not busy}\}$. In this example, the emission matrix, $A$ and transition matrix, $B$ are given below based on the quantities decided in \ref{TrEm}. 
\begin{align*}
    A = \begin{bmatrix}
    .7 & .3 \\
    .6 & .4 
    \end{bmatrix} \qquad 
     B = \begin{bmatrix}
    .2 & .8 \\
    .9 & .1
    \end{bmatrix} 
\end{align*}

\end{example}







\subsubsection{Application to Map Matching}

From the survey from Chao \cite{C}, HMM models for map matching have the following setup. The observed quantities in the HMM for the map matching problem are the sequence of geospatial data points and the hidden variable are the possible edges on the road network. The transition probabilities describe likelihood of the route containing some edge, given the previous edge, but the emission probabilities describe the probability that of trajectory point given some edge in the road network. The choice of these parameter differentiates existing HMM models. After the parameters are chosen, one can compute the route in the road network with the highest probability.  

%The design of Hidden Markov Models has a simple correspondence to the map matching process. Each trajectory point is considered a noisy observation, while the ground truth (the edge the vehicle is positioned on) is considered an unobserved state. In particular, because each trajectory point has measurement error, every edge proximate to the trajectory point has an associated emission probability, indicating the likelihood that the actual vehicle location is currently in that state. As additional trajectory points are considered, the transitions can be assigned to one of the candidate states depending on the transition probability between candidates. By applying the Viterbi algorithm to the HMM, we can obtain a sequence of hidden states with the maximum likelihood. /cite{Chao}

%The HMM method allows for a great variety of implementations, based on how emission probabilities and transition probabilities are defined (and weighed?). Thus, there is no 'optimal' HMM method for any possible trajectory.

%Here we will outline of HMM approach.




% Describe open problems in map matching

% \subsection{Literature Review}

\subsection{Mathematical Background}


%Here we can include an introduction to optimal transport theory and the necessary Riemannian geometry.

\subsubsection{A brief introduction of (discrete) optimal transport theory} \label{IntroOfOT}

We will briefly describe discrete optimal transport theory (see also \cite{FG,Sa,Vi}, etc.).
Consider transporting sand from a sand pile at $x_1,\ldots,x_n$ to a hole at $y_1,\ldots,y_m$.
Note that $n,m\in\N$ are independent {\color{red}of mutually.} 
Suppose that each sand pile $x_1,\dots,x_n$ has $\mu(x_1),\ldots,\mu(x_n)$ amount of sand, respectively, and each hole $y_1,\dots,y_m$ {\color{red} has $\nu(y_1),\dots,\nu(y_m)$ amount of sand allowed}, respectively.
Moreover, we assume that the cost of transporting from a sand pile of $x_i$ to a hole of $y_j$ is linearly dependent on their distance $d(x_i,y_j)$: 
it costs $d(x_i,y_j)\pi(x_i,y_j)$ to transport sand of mass $\pi(x_i,y_j)$ from the sand pile at $x_i$ to the hole at $y_j$.
Since the sum of the amount of sand transported from each $x_i$ equals the sum of the amount of sand placed in each hole $y_j$, the following holds:
\begin{align}
    \dis \sum_{i=1}^n \mu(x_i) = \sum_{j=1}^m \nu(y_j). \label{total mass}
\end{align}
For simplicity, we normalize both sides of \eqref{total mass} to be 1.
Then, $\mu,\nu$ can be regarded as probability measures, respectively.
Optimal transport problem is the problem such minimizing total mass which cost the transport.
In other words, we consider the following the minimizing problem.
\begin{align*}
\begin{aligned}
    & \text{minimize} 
        & \sum_{i=1}^n \sum_{j=1}^m d(x_i,y_j)\pi(x_i,y_j) & & \label{object func.} \\
    & \text{subject to} 
        & \pi(x_i,y_j)\ge 0 & \qquad \text{for all } i=1,\ldots,n,\, j=1,\ldots,m, \\
        & & \mu(x_i)=\sum_{j=1}^m \pi(x_i,y_j) & \qquad \text{for all } i=1,\ldots,n, \\
        & & \mu(y_j)=\sum_{i=1}^n \pi(x_i,y_j) & \qquad \text{for all } j=1,\ldots,m. 
\end{aligned}
\end{align*}
We call the map $\pi$ that satisfies these conditions the \emph{optimal transport plan} or the \emph{coupling} of $\mu,\nu$.
$\Pi(\mu,\nu)$ denotes a set of all couplings of $\mu,\nu$.
\begin{definition}[$L^1$-Wasserstein distance]
For probability measures $\mu,\nu$ with $\supp\mu=x_1,\ldots,x_n$ and $\supp\nu=y_1,\ldots,y_m$, we define 
\begin{align}
    W_1(\mu,\nu) \:= \inf_{\pi\in\Pi(\mu,\nu)} \sum_{i=1}^n \sum_{j=1}^m d(x_i,y_j)\pi(x_i,y_j). \label{Wasserstein}
\end{align}
\end{definition}
Under the appropriate conditions, $W_1$ is a distance function on the probability measure space.
Although $\Pi(\mu,\nu)$ is an infinite set since the amount of sand transported can be continuously varied, this is known to be a bounded closed convex set.
Hence, the right hand side of \eqref{Wasserstein} attains the minimun value.



\section{Our Approach}

\begin{itemize}
    \item Description of Wasserstein Distance Technique
    \item Description of inner product method 
    \item Describe data sets of interest 
\end{itemize}

\subsection{The method using Wasserstein Distance}

\subsubsection{The case in which input data is only the trajectory and timestamps} \label{input:tra&time}

We assume that the input data on trajectory is only its coordinates and timestamps.
We {\color{red}consider the case }that the road network graph is a square and the trajectories is located around its diagonal as the simplest model of situations where we cannot judge the passing route.
Suppose that the trajectory $p_1,\ldots,p_n$ is observed near the diagonal as shown in \autoref{square model}.
Although the trajectory are drawn in a zigzag pattern in \autoref{square model}, this arrangement can be used for anything near the diagonal line.
Here, let us assume that we know from the information of timestamps that the mover was from $v_1$ to $v_4$.
Then, it is difficult to judge from this information only whether $v_1\to v_2\to v_4$ ( we call this \emph{route $A$}) or $v_1\to v_3\to v_4$ ( we call this \emph{route $B$}).
Therefore, we propose the method of route determination based on the optimal transport theory described in \autoref{IntroOfOT}.

\begin{figure}[H]
\begin{tabular}{ccc}
\begin{minipage}{0.43\hsize}
\begin{center}
\begin{tikzpicture}[every node/.style={circle,fill=white}]
\node (p1) at (1,3.6) {\red($p_1$)};
\node (p2) at (0.5,2.9) {\red($p_2$)};
\node (p3) at (1.5,3.1) {\red($p_3$)};
\node (pn-1) at (3.5,1.2) {\red($p_{n-1}$)};
\node (pn) at (3.1,0.3) {\red($p_n$)};
\draw (0,4) node (v1) [draw] {$v_1$};
\draw (4,4) node (v2) [draw] {$v_2$};
\draw (0,0) node (v3) [draw] {$v_3$};
\draw (4,0) node (v4) [draw] {$v_4$};
\draw (v1)--(v2);
\draw (v2)--(v4);
\draw (v4)--(v3);
\draw (v3)--(v1);
\draw[dashed] (v1)--(v4);
\draw[red, dashed] (p3)--(pn-1);
\draw[red, dashed] (p2)--(pn);
\draw[arrows=->, thick, draw=blue] ($(v1)+(0.15,0.6)$) to ($(v2)+(0.3,0.6)$);
\draw[arrows=->, thick, draw=blue] ($(v2)+(0.6,0.6)$) to ($(v4)+(0.6,0)$);
\draw[arrows=->, thick, draw=green] ($(v1)+(-0.6,-0.15)$) to ($(v3)+(-0.6,-0.3)$);
\draw[arrows=->, thick, draw=green] ($(v3)+(-0.6,-0.6)$) to ($(v4)+(0,-0.6)$);
\node at (5.5,2) {{Route $A$}};
\node at (-1.5,2) {{Route $B$}};
\end{tikzpicture}
\caption{The case where the trajectory $p_1,\dots,p_n$ is observed near the diagonal of a square road network.} \label{square model}
\end{center}
\end{minipage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{minipage}{0.1\hsize}
\begin{center}
\end{center}
\end{minipage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{minipage}{0.43\hsize}
\begin{center}
\begin{tikzpicture}[every node/.style={circle,fill=white}]
\node (p1) at (1,3.6) {\footnotesize{\red($1/n$)}};
\node (p2) at (0.5,2.9) {\footnotesize{\red($1/n$)}};
\node (p3) at (1.5,3.1) {\footnotesize{\red($1/n$)}};
\node (pn-1) at (3.5,1.2) {\footnotesize{\red($1/n$)}};
\node (pn) at (3.1,0.3) {\footnotesize{\red($1/n$)}};
\draw (0,4) node (v1) [draw] {$v_1$};
\draw (4,4) node (v2) [draw] {$v_2$};
\draw (0,0) node (v3) [draw] {$v_3$};
\draw (4,0) node (v4) [draw] {$v_4$};
\draw (v1)--(v2);
\draw (v2)--(v4);
\draw (v4)--(v3);
\draw (v3)--(v1);
\draw[dashed] (v1)--(v4);
\draw[red, dashed] (p3)--(pn-1);
\draw[red, dashed] (p2)--(pn);
\end{tikzpicture}
\caption{A probability measure $\mu_\mathbb{P}$ on the trajectory.The weight $1/n$ is placed on the trajectory points $p_1,\dots,p_n$ respectively.} \label{mu_P}
\end{center}
\end{minipage}
\end{tabular}
\end{figure} 

By introducing the following three types of probability measures, we reduce the problem of route determination to the framework of an optimal transportation problem: probability measures associated with the trajectory and route $A,B$.
In other words, our idea is to quantify the distance between the trajectory set $\mathbb{P}=\{p_1,\ldots,p_n\}$ and each route by measuring Wasserstein distance between probability measures associated with the trajectory and route.

First, we introduced the probability measure $\mu_\mathbb{P}$ associated with the trajectory set $\mathbb{P}$.

\begin{definition}[A probability measure associated with the trajectory set]
We define a probability measure $\mu_\mathbb{P}$ as by putting weights of $1/n$ on each points in $\mathbb{P}$ (see also \autoref{mu_P}):
\begin{align}
    \mu_\mathbb{P} \:= \frac{1}{n}\de_{p_1}+\cdots+\frac{1}{n}\de_{p_n}. 
\end{align}
\end{definition}

Then, we introduced the probability measures associated with the route $A$, $B$ by dividing each routes into $m+1$ equal parts and putting weights by $1/m$ on the points that are its thresholds. 

\begin{definition}[The probability measures associated with the route $A$ and $B$]
We divide the route $A$ into $m+1$ equal parts along the edges, and denote the threshold points as $a_1,\ldots,a_m$, starting from the point closest to $v_1$.
We define a probability measure $\nu_{A,m}$ as by putting weights of $1/m$ on each threshold points on the route $A$ (see also \autoref{nu_A}):
\begin{align}
    \nu_{A,m} \:= \frac{1}{m}\de_{a_1}+\cdots+\frac{1}{m}\de_{a_m}. 
\end{align}
We define $\nu_{B,m}$ in exactly the same way (see also \autoref{nu_B}):
\begin{align}
    \nu_{B,m} \:= \frac{1}{m}\de_{b_1}+\cdots+\frac{1}{m}\de_{b_m}.
\end{align}
\end{definition}

\begin{remark}
In the above definition, $n$ and $m$ are independent, while $m$, the number of supports of $\nu_{A,m}$ and $\mu_{B,m}$, are both equal: 
for any $m\in\N$, $\#\supp\mu_{A,m}=\#\supp\nu_{A,m}\;(=m)$.
If $m$ is odd and can be expressed as $m=2\ell-1$, then the threshold points $a_\ell$ and $b_\ell$ coincide with the nodes $v_2$ and $v_3$, respectively.
\end{remark}

\begin{figure}[H]
\begin{tabular}{ccc}
\begin{minipage}{0.43\hsize}
\begin{center}
\begin{tikzpicture}[every node/.style={circle,fill=white}]
\node (a1) at (0.7,3.7) {\footnotesize{\blue($a_1$)}};
\node (a2) at (1.15,3.7) {\footnotesize{\blue($a_2$)}};
\draw[dashed, blue] (1.4,3.7)--(3.6,3.7);
\draw[dashed, blue] (3.7,3.6)--(3.7,1);
\node (am-1) at (3.5,1.15) {\footnotesize{\blue($a_{m-1}$)}};
\node (am) at (3.6,0.7) {\footnotesize{\blue($a_m$)}};
\draw (0,4) node (v1) [draw] {$v_1$};
\draw (4,4) node (v2) [draw] {$v_2$};
\draw (0,0) node (v3) [draw] {$v_3$};
\draw (4,0) node (v4) [draw] {$v_4$};
\draw (v1)--(v2);
\draw (v2)--(v4);
\draw (v4)--(v3);
\draw (v3)--(v1);
\fill [blue] (0.7,4) circle (0.1);
\fill [blue] (1.15,4) circle (0.1);
\fill [blue] (3.3,4) circle (0.1);
\fill [blue] (4,3.3) circle (0.1);
\fill [blue] (4,1.15) circle (0.1);
\fill [blue] (4,0.7) circle (0.1);
%\draw[dashed] (v1)--(v4);
\draw[arrows=->, thick, draw=blue] ($(v1)+(0.15,0.6)$) to ($(v2)+(0.3,0.6)$);
\draw[arrows=->, thick, draw=blue] ($(v2)+(0.6,0.6)$) to ($(v4)+(0.6,0)$);
\node at (5.5,2) {{Route $A$}};
\end{tikzpicture}
\caption{A probability measure $\nu_{A,m}$ associated with the route $A$.
The edges $(v_1,v_2)$ and $(v_2,v_4)$ forming the route $A$ are divided into $m+1$ equal parts, each with $1/m$ weight on its threshold points $a_1,\ldots,a_m$.} \label{nu_A}
\end{center}
\end{minipage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{minipage}{0.1\hsize}
\begin{center}
\end{center}
\end{minipage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{minipage}{0.43\hsize}
\begin{center}
\begin{tikzpicture}[every node/.style={circle,fill=white}]
\node (b1) at (0.4,3.3) {\footnotesize{\green($b_1$)}};
\node (a2) at (0.4,2.85) {\footnotesize{\green($b_2$)}};
\draw[dashed, green] (0.4,2.5)--(0.4,0.5);
\draw[dashed, green] (0.5,0.3)--(2.4,0.3);
\node (am-1) at (2.8,0.3) {\footnotesize{\green($b_{m-1}$)}};
\node (am) at (3.5,0.3) {\footnotesize{\green($b_m$)}};
\draw (0,4) node (v1) [draw] {$v_1$};
\draw (4,4) node (v2) [draw] {$v_2$};
\draw (0,0) node (v3) [draw] {$v_3$};
\draw (4,0) node (v4) [draw] {$v_4$};
\draw (v1)--(v2);
\draw (v2)--(v4);
\draw (v4)--(v3);
\draw (v3)--(v1);
\fill [green] (0,3.3) circle (0.1);
\fill [green] (0,2.85) circle (0.1);
\fill [green] (0,0.7) circle (0.1);
\fill [green] (0.7,0) circle (0.1);
\fill [green] (2.85,0) circle (0.1);
\fill [green] (3.3,0) circle (0.1);
%\draw[dashed] (v1)--(v4);
\draw[arrows=->, thick, draw=green] ($(v1)+(-0.6,-0.15)$) to ($(v3)+(-0.6,-0.3)$);
\draw[arrows=->, thick, draw=green] ($(v3)+(-0.6,-0.6)$) to ($(v4)+(0,-0.6)$);
\node at (-1.5,2) {{Route $B$}};
\end{tikzpicture}
\caption{A probability measure $\nu_{B,m}$ associated with the route $B$.
The edges $(v_1,v_3)$ and $(v_3,v_4)$ forming the route $B$ are divided into $m+1$ equal parts, each with $1/m$ weight on its threshold points $b_1,\ldots,b_m$.} \label{nu_B}
\end{center}
\end{minipage}
\end{tabular}
\end{figure}

\begin{definition}
For $\mu_\mathbb{P}$, $\nu_{A,m}$, $\nu_{B,m}$, we define 
\begin{align*}
    f(A,m) \:= W_1\big(\mu_\mathbb{P},\nu_{A,m}\big), \qquad f(B,m) \:= W_1\big(\mu_\mathbb{P},\nu_{B,m}\big).
\end{align*}
\end{definition}

As $m$ is increased, $\supp\nu_{A,m}$ and $\supp\nu_{B,m}$ approaches the route $A$: $(v_1\to v_2\to v_4)$ and route $B$: $(v_1\to v_3\to v_4)$ respectively.
Our idea is that we can judge which route is closer to the trajectory set $\mathbb{P}$ by computing $f(A,m)-f(B,m)$ for a sufficiently large $m\in\N$.
Then, we need to show the following.

\begin{prob} \label{monotonicity}
There exists a $\ttilde{m}\in\N$ such that $f(A,m)-f(B,m)$ is a monotone function for any $m\in\N$ more than $\ttilde{m}$.
\end{prob}

We can judge which route the trajectory set is closer to by checking the sign of $f(A,m)-f(B,m)$ for a sufficiently large $m$ if we can prove \autoref{monotonicity}.
Hence, if $f(A,m)<f(B,m)$ holds, then we can conclude that the trajectory set is closer the route $A$, which is the real route.

\begin{remark}
Although $f(A,m)$ and $f(B,m)$ take finite values for any $m\in\N$, they might not converge as $m\to\infty$.
In fact, although we would conject them to converge if $m$ diverges to infinity in an even or odd state, respectively, their values may be different, i.e. their values may oscillate as $m\to\infty$.
\end{remark}

\begin{remark}
Note that the set of trajectory points is an imputed finite set, and the root is a polyline, that is, a set of infinite points.
The point-to-curve method projects from the trajectory point to the edges that compose the candidate route, so it is actually a point-to-(point on curve) iteration.
In contrast, our method transports a set of trajectory points to a candidate route, in other words, it is a (trajectory set)-to-route process.
In this sense, we want the method to be robust to observation errors.
\end{remark}

\subsubsection{The case in which input data is only the trajectory, timestamps, speed and angles} %\label{input:tra&time}

We proposed the method of qualyfing the distance between the trajectry set and candidate routes by using the information of coordinates of trajectry points only in \autoref{input:tra&time}.
We would like to develop this discussion in the case where we also have information on speed and angle.


%$f(A,m)$の値を計算する際、我々は$\sum_{i=1}^n \sum_{j=1}^m d(p_i,a_j)\pi(p_i,a_j)$をloss functionと見なして線形計画問題を解くことになる(see \eqref{object func.} in \autoref{IntroOfOT}).
%我々のloss functionは
%この場合、speedやangleの情報を
%\eqref{object func.} in \autoref{IntroOfOT}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The method using Euclidean inner product}

\subsubsection{Abstract}
We considered making the geometric method more accurate by taking into account not only the position of each trajectory point but also the vector connecting each point, calculating the inner product of that vector and the edge of the route, and measuring how close the oriented directions are. This method have similarities with topological methods.

\subsubsection{Specific procedure}
%we process trajectory points that seems to have little error and no influence on determining the edges. Take balls centered at each vertex of the road network with a radius small enough that they do not intersect each other. Then, we replace the position data of trajectory points which are contained in any of those balls to the center of the ball which is a vertex of road network graph. This process is a variant of point-to-point method in geometric methods.
%Next we determine the edge by calculating inner product. This step is the main part of our method. 
We list all candidate routes by point-to-point method and point-to-curve method.
That is, We determine the closest vertex and edge of road network for each trajectory points and list routes that are composed of those vertex and edges.
Then we define score for each edge contained in the candidates and adopt the one which has the biggest score as the route.  
The factors that determine the score are the inner product of the line segment connecting the trajectory points and the edge, and the closeness of their positions.

The specific procedure for defining score is as follows.
We define vectors $v_{i} = x_{i+1}-x_{i}$ and $v_{e} = f-s$ for a pair of trajectory points $(x_{i}, t_{i}), (x_{i+1}, t_{i+1})$ and each edge $e = (s,f,l)$ contained in candidates routes.
Then we define $P(v_{i}, v_{e}) := (\frac{v_{i}}{|v_{i}|}, \frac{v_{e}}{|v_{e}|})$
Next, we take a perpendicular line from each trajectory point $x_{i}$ to each edge $e$ and define $L_{i,e}$ as the length of the line.
We define the score $S(e) := \sum_{i}P(v_{i}, v_{e}) + \frac{1}{1+L_{i,e}}$ for each edge.

This method has some points in common with the method called the topological method, but it is considered to be a simpler method because it does not require the calculation of angles and the procedures of case classification according to their magnitudes, which are performed in the topological method.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Implementation}


%
{\color{blue} We will test ? This is a proposal, not a summary of what we have done.}
We tested these methods using Jupyter notebooks. Within the notebooks we implement them in Python and test them against the BDD100K open data set provided by Berkeley\cite{berkeley}. % Describe what we used for ground truths
We also implemented two standard map matching methods to use as a benchmark: 
\begin{itemize}
    \item Fast Map Matching \url{https://github.com/cyang-kth/fmm}
    \item A simple Extended Kalman Filter % Might use another source, might make my own
\end{itemize}

Furthermore, the Jupyter notebooks develop a framework for implementing and testing other algorithms against data sets. One issue that pervades this field of research is the lack of standard formatting-- namely, there are several different GIS data types which differ slightly, and in particular none of these formats are well-suited for containing IMU data. Our notebooks provide a rudimentary fusion method to align asynchronous data and incorporates IMU data into GPX/GeoDataFrame in a sensible manner. 

The benefit these data types provide is being simple (human-readable and easy to convert from/to) and lightweight (quick to access and manipulate, and simple to compress). Moreover, it is easy to convert from these data types to others, unlike proprietary formats such as ESRI ShapeFile. Testing algorithms against data sets then reduces to formatting your inputs/outputs properly. This is designed for accessibility, so other students or researchers can experiment with their own ideas and obtain results more easily. %We also hope this will encourage the greater community to publish their data sets in these formats, so to increase standardization.

The code written for the project can be found at \url{https://github.com/gjgress/G-RIPS-2022-Mitsubishi-A}.

\section{Deliverable}
\begin{itemize}
    \item Three novel approaches to map matching 
    \item Comparison of these methods with current method
    \item Python scripts and Jupyter notebooks for reproducibility
\end{itemize}
 

\newpage
\section{Timeline}
The following is our proposed timeline for the project. 

\subsection*{Week 1-2}
\begin{itemize}[noitemsep]
    \item Create project proposal
    \item Develop Python framework to manipulate map structures and set up data sets
\end{itemize}

% \subsection*{Week 2}
% \begin{itemize}[noitemsep]
%     \item 
% \end{itemize}

\subsection*{Week 3}
\begin{itemize}[noitemsep]
    \item 
\end{itemize}

\subsection*{Week 4}
\begin{itemize}[noitemsep]
    \item 
\end{itemize}

\subsection*{Week 5}
\begin{itemize}[noitemsep]
    \item 
\end{itemize}

\subsection*{Week 6}
\begin{itemize}[noitemsep]
    \item 
\end{itemize}

% \subsection*{Week 7}
% \begin{itemize}[noitemsep]
%     \item 
% \end{itemize}

\subsection*{Week 7-8}
\begin{itemize}[noitemsep]
    \item Write final report
\end{itemize}

\newpage
\bibliographystyle{unsrt}
% \bibliography{bibliography} 
\begin{thebibliography}{AA}
\bibitem[BK]{BK}  D. Bernstein, A. Kornhauser,\textit{An introduction to map-matching for personal navigation assistants,} \url{http://www.njtude.org/reports/mapmatchintro.pdf },1996
\bibitem[C]{C} P. Chao and  Y. Xu and  W. Hua and X. Zhou, \textit{ A survey on map-matching algorithms}, Springer, Cham. (2020)
\bibitem[FG]{FG} A. Figalli and F. Glaudo, \textit{An invitation to optimal transport, Wasserstein distances, and gradient flows}, EMS Textbooks in Mathematics. EMS Press (2021).
\bibitem[Q]{Q} M.A. Quddus, W.Y. Ochieng, and R.B. Noland. \textit{Current map-matching algorithms for transport applications: State-of-the art and future research directions.} 2007.
\bibitem[Sa]{Sa} F. Santambrogio, \textit{Optimal transport for applied mathematicians. Calculus of variations, PDEs, and modeling}, Progress in Nonlinear Differential Equations and their Applications, Birkhäuser/Springer, Cham. (2015).
\bibitem[Vi]{Vi} C. Villani, \textit{Optimal Transport. Old and New}, Springer-Verlag. (2008).
\end{thebibliography}


\end{document}
